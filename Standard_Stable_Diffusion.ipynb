{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishalPrem1994/AiGenPlayground/blob/main/Standard_Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDfa5QD6drKJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsubXYnqcJVK"
      },
      "outputs": [],
      "source": [
        "#@markdown Download Important Stuff\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrDcL72pckIi"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94PfIJQLa7C1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "torch.cuda.empty_cache()\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "model_id = \"nitrosocke/Arcane-Diffusion\" #@param {type:\"string\"}\n",
        "device = \"cuda\"\n",
        "seed = 70034 #@param {type:\"string\"}\n",
        "g_cuda.manual_seed(seed)\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch.float16)\n",
        "pipe = pipe.to(device)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RIY0_yUcI4h",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "prompt = \"girl with a gun, arcane style, at night,  fit, gorgeous, beautiful, ((intricate)), ((highly detailed)), sharp focus, clear, cinematic, symmetrical, vogue, editorial, smooth, sharp focus\"#@param {type:\"string\"}\n",
        "negative_prompt = \"far away, black and white, blurry face, wrong eyes, extra hands, extra legs, wierd eyes, disfigured face, (((backlight))), (((dark face))), ((cropped head)), ((out of frame)), ((long neck)), deformed, cripple, ugly, additional arms, additional legs, additional head, two heads, multiple people, group of people\" #@param {type:\"string\"}\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "guidance_scale = 8 #@param {type:\"number\"}\n",
        "num_inference_steps = 30 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "images = pipe(\n",
        "    prompt,\n",
        "    height=height,\n",
        "    width=width,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_images_per_prompt=num_samples,\n",
        "    num_inference_steps=num_inference_steps,\n",
        "    guidance_scale=guidance_scale,\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)   "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiFnV1QsTLJ10bbjQJlnbv",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}